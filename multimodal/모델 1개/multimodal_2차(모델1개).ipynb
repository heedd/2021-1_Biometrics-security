{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7qOGWDALJy8"
   },
   "source": [
    "# 모듈 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OVQiM5GMLJy-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import models, layers, optimizers, utils, Model, regularizers\n",
    "from keras.utils import np_utils #to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score,f1_score,recall_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7d4hyAVLJzC"
   },
   "source": [
    "# 얼굴 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y0To1jM9LJzE"
   },
   "outputs": [],
   "source": [
    "path='C:/Users/clari/Desktop/multimodal2/model2/face'\n",
    "\n",
    "face_images = []\n",
    "labels = []\n",
    "def crop_images(path, images):\n",
    "    for img in sorted(os.listdir(path)):\n",
    "        img_array = cv.imread(os.path.join(path, img))/255\n",
    "        face_images.append(img_array)\n",
    "        label = np_utils.to_categorical(int(img[:3]), 64)\n",
    "        labels.append(label)\n",
    "\n",
    "crop_images(path, face_images)\n",
    "face_images = np.array(face_images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ab35zAvC2hHB"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "trainDataGen = ImageDataGenerator(\n",
    "                                 width_shift_range=0.05,\n",
    "                                 height_shift_range=0.05,\n",
    "                                 brightness_range=[0.7, 1.3],\n",
    "                                 horizontal_flip=True,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Km6pTMRt3Uux"
   },
   "outputs": [],
   "source": [
    "path2='C:/Users/clari/Desktop/multimodal2/model2/aug/face_aug_small2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CiKsXY432hDg"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "num=4 #레이블 당 개수\n",
    "im=[]\n",
    "\n",
    "for img in face_images :\n",
    "    im.append(img)\n",
    "    im=np.array(im)\n",
    "    for batch in trainDataGen.flow(im, batch_size=1, save_to_dir=path2,\n",
    "                                   save_prefix=str(format(int(i/num),'03')), save_format='png'):\n",
    "        j += 1\n",
    "        if j > 7:\n",
    "            break\n",
    "    j = 1\n",
    "    i+=1\n",
    "    im=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2v77iaeh2hAe"
   },
   "outputs": [],
   "source": [
    "def append_images(path, images, labels):\n",
    "    a=1\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv.imread(os.path.join(path, img))\n",
    "        images = np.append(images, [img_array], axis = 0)\n",
    "        label = np_utils.to_categorical(int(img[:3]), 64)\n",
    "        labels = np.append(labels, [label], axis=0)\n",
    "    return images, labels\n",
    "        \n",
    "face_images, labels = append_images(path2, face_images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuVbJfzQLJzK"
   },
   "source": [
    "# 홍채 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4M9G8eh9LJzL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='C:/Users/clari/Desktop/multimodal2/model2/iris'\n",
    "\n",
    "#786 576\n",
    "sc=0.1\n",
    "\n",
    "iris_images = []\n",
    "\n",
    "def img_trim (img):     \n",
    "    x = 150; y = 90;\n",
    "    w = 476; h = 430;\n",
    "    img_trim = img[y:y+h, x:x+w]\n",
    "    return img_trim\n",
    "\n",
    "def crop_images(path, images):\n",
    "    for img in sorted(os.listdir(path)):\n",
    "        img_array = cv.imread(os.path.join(path, img))/255.0\n",
    "        img_array = cv.resize(img_trim(img_array), (0,0), fx=sc, fy=sc)\n",
    "        iris_images.append(img_array)\n",
    "    \n",
    "\n",
    "crop_images(path, iris_images)\n",
    "iris_images = np.array(iris_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "J9jPS3Nm2uKk"
   },
   "outputs": [],
   "source": [
    "trainDataGen2 = ImageDataGenerator(\n",
    "                                 width_shift_range=0.05,\n",
    "                                 height_shift_range=0.05,\n",
    "                                 brightness_range=[0.6, 1.3]\n",
    "                                # horizontal_flip=True,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dXKAAJq548ir"
   },
   "outputs": [],
   "source": [
    "path3='C:/Users/clari/Desktop/multimodal2/model2/aug/iris_aug_small2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZW0rCjvH2uTU"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "im=[]\n",
    "num=4\n",
    "\n",
    "for img in iris_images :\n",
    "    im.append(img)\n",
    "    im=np.array(im)\n",
    "    for batch in trainDataGen2.flow(im, batch_size=1, save_to_dir=path3, save_prefix=format(int(i/num),'03'), save_format='png'):\n",
    "        j += 1\n",
    "        if j > 7:\n",
    "            break\n",
    "    j = 1\n",
    "    i+=1\n",
    "    im=[]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Yrwj4FAi2udJ"
   },
   "outputs": [],
   "source": [
    "def append_images(path, images):\n",
    "    a=1\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv.imread(os.path.join(path, img))\n",
    "        images = np.append(images, [img_array], axis = 0)\n",
    "    return images\n",
    "\n",
    "iris_images = append_images(path3, iris_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 56, 46, 3)\n",
      "(2048, 43, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "print(face_images.shape)\n",
    "print(iris_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 48, 3)\n",
      "(43, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "#face 112, 92, 3\n",
    "#iris 129, 143, 3\n",
    "image = []\n",
    "\n",
    "for img in face_images : \n",
    "    img = cv.resize(img, (43, 48))\n",
    "    img = img.transpose(1, 0, 2)\n",
    "    image.append(img) \n",
    "    \n",
    "image = np.array(image)\n",
    "print(image[0].shape)\n",
    "print(iris_images[0].shape)\n",
    "\n",
    "images = []\n",
    "for i in range(len(image)) :\n",
    "    images.append(np.concatenate((image[i],iris_images[i]),axis=0))\n",
    "\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images : (2048, 86, 48, 3)\n",
      "labels : (2048, 64)\n"
     ]
    }
   ],
   "source": [
    "print('images :',images.shape)\n",
    "print('labels :',labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9M9KdiaLJzQ"
   },
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=layers.Input(shape=(86, 48, 3))\n",
    "\n",
    "x = input\n",
    "x = layers.Conv2D(filters = 32, kernel_size = (3,3), padding='Same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size = (2,2))(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 32, kernel_size = (3,3), padding='Same', activation='relu')(x)\n",
    "x = layers.AveragePooling2D(pool_size = (2,2))(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 64, kernel_size = (3,3), padding='Same', activation='relu')(x)\n",
    "x = layers.AveragePooling2D(pool_size = (2,2))(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 128, kernel_size = (3,3), padding='Same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size = (2,2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(50, kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation='softmax')(x)\n",
    "model = Model(inputs= input, outputs=x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDffGRpNLJzc"
   },
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4QLNFXyFLJze"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1\n",
      "Epoch 1/60\n",
      "48/48 [==============================] - 11s 170ms/step - loss: 4.2296 - accuracy: 0.0588\n",
      "Epoch 2/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 2.9481 - accuracy: 0.3441\n",
      "Epoch 3/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 1.9554 - accuracy: 0.6687\n",
      "Epoch 4/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 1.3025 - accuracy: 0.8273\n",
      "Epoch 5/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 0.9723 - accuracy: 0.8569\n",
      "Epoch 6/60\n",
      "48/48 [==============================] - 8s 175ms/step - loss: 0.8000 - accuracy: 0.8741\n",
      "Epoch 7/60\n",
      "48/48 [==============================] - 8s 175ms/step - loss: 0.6618 - accuracy: 0.8780\n",
      "Epoch 8/60\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.5148 - accuracy: 0.8964\n",
      "Epoch 9/60\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.3943 - accuracy: 0.9408\n",
      "Epoch 10/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 0.2593 - accuracy: 0.9611\n",
      "Epoch 11/60\n",
      "48/48 [==============================] - 8s 167ms/step - loss: 0.1918 - accuracy: 0.9745\n",
      "Epoch 12/60\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.1247 - accuracy: 0.9880\n",
      "Epoch 13/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0936 - accuracy: 0.9934\n",
      "Epoch 14/60\n",
      "48/48 [==============================] - 8s 167ms/step - loss: 0.0743 - accuracy: 0.9949\n",
      "Epoch 15/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0471 - accuracy: 0.9970\n",
      "Epoch 16/60\n",
      "48/48 [==============================] - 8s 173ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "48/48 [==============================] - 8s 168ms/step - loss: 0.0336 - accuracy: 0.9985\n",
      "Epoch 18/60\n",
      "48/48 [==============================] - 9s 179ms/step - loss: 0.0311 - accuracy: 0.9991\n",
      "Epoch 19/60\n",
      "48/48 [==============================] - 9s 179ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "48/48 [==============================] - 8s 167ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0135 - accuracy: 0.9999\n",
      "Epoch 23/60\n",
      "48/48 [==============================] - 9s 179ms/step - loss: 0.0173 - accuracy: 0.9997\n",
      "Epoch 24/60\n",
      "48/48 [==============================] - 9s 178ms/step - loss: 0.0172 - accuracy: 0.9988\n",
      "Epoch 25/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 0.0178 - accuracy: 0.9992\n",
      "-------------------------------------------------------------------------------\n",
      "Fold2\n",
      "Epoch 1/60\n",
      "48/48 [==============================] - 8s 173ms/step - loss: 0.0275 - accuracy: 0.9974\n",
      "Epoch 2/60\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 3/60\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 4/60\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 5/60\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 6/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 7/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "48/48 [==============================] - 8s 167ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "48/48 [==============================] - 8s 170ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "48/48 [==============================] - 8s 173ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "48/48 [==============================] - 8s 165ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "48/48 [==============================] - 8s 177ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "48/48 [==============================] - 8s 169ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "48/48 [==============================] - 8s 169ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "48/48 [==============================] - 8s 167ms/step - loss: 0.0023 - accuracy: 1.00004s - loss: 0.0023 - accu - ETA\n",
      "Epoch 24/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 0.0020 - accuracy: 1.00001s - loss: 0.0020 - \n",
      "Epoch 25/60\n",
      "48/48 [==============================] - 8s 168ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "48/48 [==============================] - 8s 175ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "48/48 [==============================] - 8s 174ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "48/48 [==============================] - 8s 170ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "48/48 [==============================] - 8s 167ms/step - loss: 0.0016 - accuracy: 1.00000s - loss: 0.0016 - accuracy: \n",
      "Epoch 30/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "48/48 [==============================] - 8s 175ms/step - loss: 0.0215 - accuracy: 0.9954\n",
      "Epoch 32/60\n",
      "48/48 [==============================] - 8s 177ms/step - loss: 0.2607 - accuracy: 0.9440\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clari\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3\n",
      "Epoch 1/60\n",
      "48/48 [==============================] - 8s 168ms/step - loss: 0.0973 - accuracy: 0.9857\n",
      "Epoch 2/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 0.0304 - accuracy: 0.9954\n",
      "Epoch 3/60\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.0154 - accuracy: 0.9980\n",
      "Epoch 4/60\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 5/60\n",
      "48/48 [==============================] - 8s 177ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 6/60\n",
      "48/48 [==============================] - 8s 174ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 7/60\n",
      "48/48 [==============================] - 8s 170ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "48/48 [==============================] - 8s 168ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "48/48 [==============================] - 8s 168ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "48/48 [==============================] - 8s 165ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "48/48 [==============================] - 8s 165ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "48/48 [==============================] - 8s 167ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "48/48 [==============================] - 8s 168ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.0014 - accuracy: 1.00002s -\n",
      "Epoch 16/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "48/48 [==============================] - 8s 172ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "48/48 [==============================] - 8s 170ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0114 - accuracy: 0.9987\n",
      "Epoch 23/60\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "-------------------------------------------------------------------------------\n",
      "Fold4\n",
      "Epoch 1/60\n",
      "48/48 [==============================] - 8s 170ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 2/60\n",
      "48/48 [==============================] - 8s 167ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 3/60\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 4/60\n",
      "48/48 [==============================] - 8s 170ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 5/60\n",
      "48/48 [==============================] - 8s 173ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 6/60\n",
      "48/48 [==============================] - 8s 173ms/step - loss: 0.0023 - accuracy: 0.9993TA: 2s - l\n",
      "Epoch 7/60\n",
      "48/48 [==============================] - 8s 164ms/step - loss: 0.0124 - accuracy: 0.9993\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='loss',     # 모니터 기준 설정 (loss) \n",
    "                              patience = 3,         # 5회 Epoch동안 개선되지 않는다면 종료\n",
    "                             )\n",
    "\n",
    "#Cross validation\n",
    "num = 4\n",
    "cross = KFold(n_splits = num, shuffle = True, random_state = 2021)\n",
    "accs = [];  precision = [];  recall = [];  F1 = []\n",
    "history = []\n",
    "i = 0\n",
    "\n",
    "for train_index,test_index in cross.split(images, labels):\n",
    "    #훈련용\n",
    "    x_train = images[train_index] #(900, 56, 46, 3)\n",
    "    y_train = labels[train_index] #(900, 350)\n",
    "    #검증용\n",
    "    x_test = images[test_index] #(150, 56, 46, 3)\n",
    "    y_test = labels[test_index] #(150, 350)\n",
    "    \n",
    "    i += 1    \n",
    "    print('Fold' + str(i))\n",
    "    \n",
    "    #훈련용에 대해 model 학습시키고()\n",
    "    history.append(model.fit(x_train, y_train, epochs = 60, batch_size = 32, callbacks = earlystopping))\n",
    "    print('-------------------------------------------------------------------------------')\n",
    "        \n",
    "    y_test = np.argmax(y_test,axis = 1)\n",
    "    pred = np.argmax(model.predict(x_test), axis = 1)\n",
    "    \n",
    "    #test로 model 검증(1)\n",
    "    accs.append(accuracy_score(y_test, pred))\n",
    "    precision.append(precision_score(y_test,pred, average = 'macro'))\n",
    "    recall.append(recall_score(y_test, pred, average = 'macro'))\n",
    "    F1.append(f1_score(y_test, pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 86, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 86, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 43, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 43, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 43, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 21, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 21, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 21, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 10, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 10, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 10, 6, 128)        73856     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 5, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                96050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                3264      \n",
      "=================================================================\n",
      "Total params: 202,010\n",
      "Trainable params: 201,910\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSIGp4SHLJzj",
    "outputId": "35cec231-74ba-4fb6-9f5d-58fa1d9d53e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 훈련 결과 : \n",
      "     accs : 0.994141\n",
      "     precision : 0.995573\n",
      "     recall : 0.996801\n",
      "     F1 : 0.995890\n",
      "Fold2 훈련 결과 : \n",
      "     accs : 0.890625\n",
      "     precision : 0.916590\n",
      "     recall : 0.901296\n",
      "     F1 : 0.880802\n",
      "Fold3 훈련 결과 : \n",
      "     accs : 1.000000\n",
      "     precision : 1.000000\n",
      "     recall : 1.000000\n",
      "     F1 : 1.000000\n",
      "Fold4 훈련 결과 : \n",
      "     accs : 0.996094\n",
      "     precision : 0.995455\n",
      "     recall : 0.996205\n",
      "     F1 : 0.995496\n",
      "\n",
      "평균 훈련 결과\n",
      "     Accuracy : 0.970215\n",
      "     Precision : 0.976904\n",
      "     Recall Score : 0.973576\n",
      "     F1-Score : 0.968047\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,num+1):\n",
    "    print(\"Fold%d 훈련 결과 : \"%i)\n",
    "    print(\"     accs : %.6f\"%accs[i-1])\n",
    "    print(\"     precision : %.6f\"%precision[i-1])\n",
    "    print(\"     recall : %.6f\"%recall[i-1])\n",
    "    print(\"     F1 : %.6f\"%F1[i-1])\n",
    "\n",
    "print(\"\\n평균 훈련 결과\")\n",
    "print(\"     Accuracy : %.6f\"%np.mean(accs))\n",
    "print(\"     Precision : %.6f\"%np.mean(precision))\n",
    "print(\"     Recall Score : %.6f\"%np.mean(recall))\n",
    "print(\"     F1-Score : %.6f\"%np.mean(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY2IhYoILJzl"
   },
   "source": [
    "# 훈련 과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mrXiADatLJzm"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f89dbeb6f265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history[0].history['accuracy'])\n",
    "plt.plot(history[1].history['accuracy'])\n",
    "plt.plot(history[2].history['accuracy'])\n",
    "plt.plot(history[3].history['accuracy'])\n",
    "plt.plot(history[4].history['accuracy'])\n",
    "plt.title('model train accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['fold1', 'fold2','fold3','fold4','fold5'], loc=0)\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history[0].history['loss'])\n",
    "plt.plot(history[1].history['loss'])\n",
    "plt.plot(history[2].history['loss'])\n",
    "plt.plot(history[3].history['loss'])\n",
    "plt.plot(history[4].history['loss'])\n",
    "plt.title('model train accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['fold1', 'fold2','fold3','fold4','fold5'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJJM-oE9LJzn"
   },
   "source": [
    "# 테스트 데이터셋 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BMK6c7YjLJzp"
   },
   "outputs": [],
   "source": [
    "path='C:/Users/clari/Desktop/multimodal2/model2/face_test'\n",
    "\n",
    "test_num = []\n",
    "face_test_images = []\n",
    "def crop_test_images(path, images):\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv.imread(os.path.join(path, img))/255.0\n",
    "        face_test_images.append(img_array)\n",
    "        test_num.append(int(img[:2]))\n",
    "\n",
    "crop_test_images(path, face_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "2xor4EiB40uQ",
    "outputId": "aafcd561-aed7-426f-de63-f87731a63317"
   },
   "outputs": [],
   "source": [
    "path2='C:/Users/clari/Desktop/multimodal2/model2/iris_test'\n",
    "\n",
    "iris_test_images = []\n",
    "def crop_test_images2(path, test_images):\n",
    "    for img in os.listdir(path):\n",
    "      img_array = cv.imread(os.path.join(path, img))/255.0\n",
    "      img_array = cv.resize(img_trim(img_array), (0,0), fx=sc, fy=sc) \n",
    "      iris_test_images.append(img_array)\n",
    "\n",
    "crop_test_images2(path2, iris_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face 112, 92, 3\n",
    "#iris 129, 143, 3\n",
    "test_image = []\n",
    "\n",
    "for img in face_test_images : \n",
    "    img = cv.resize(img, (43, 48))\n",
    "    img = img.transpose(1, 0, 2)\n",
    "    test_image.append(img) \n",
    "    \n",
    "test_image = np.array(test_image)\n",
    "\n",
    "test_images = []\n",
    "for i in range(len(test_image)) :\n",
    "    test_images.append(np.concatenate((test_image[i],iris_test_images[i]),axis=0))\n",
    "\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 86, 48, 3)\n",
      "(2048, 86, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_images.shape)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "2TtZNlzQLJzr",
    "outputId": "b83c9c8c-582f-4131-befd-78b00fb569b0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred = np.argmax(model.predict(test_images), axis=1)\n",
    "\n",
    "df = pd.DataFrame({'Image': test_num, 'Answer': pred}).sort_values('Image')\n",
    "df.to_csv('C:/Users/clari/Desktop/multimodal2/model1/멀티모달_모델1개.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "yY2IhYoILJzl"
   ],
   "name": "멀티모달_1차_코드_모델1개",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
